{
  "name": "VAE rec",
  "tagline": "Variational Recurrent Auto Encoder",
  "body": "#Variational Recurrent Auto Encoder\r\nIn this post, we discussed the variational auto encoder. This post extends this idea to data with sequential nature in a recurrent network. Auto encoders belong to the family of variational inference. In normal networks we define deterministic functions and backpropagate over the gradients. In variational inference, our network contains stochastic or information layers. Also we regard the cost function from a Bayesian standpoint. All together, this makes a likelihood of our data under the model. This likelihood turns out to be intractable. Therefore, we optimize a bound on this quantity. Hence, variational inference.\r\n\r\n#Computation graph\r\nAn auto encoder always follows a similar structure: an encoder maps data to a dense representation; a decoder reconstructs the data from this representation. In normal auto encoders, the dense representation can be any layer in a neural network. As we constrain the size of this network, by backpropagation we learn a dense representation of the data.\r\n\r\n##Information layer\r\nIn variational auto encoders, the dense representation is also named information layer. This layer follows Information Theory and we reason accordingly. There is two viewpoints to this layer. They boil down to the same math\r\n  * _The information layer is a mapping to latent space_ The encoder maps the data to this latent space. More specifically, the encoder generates conditional distribution _q(z|x)_ From this conditional distribution, we sample a z for the decoder\r\n  * _The information layer is a noisy connection between encoder and decoder. This article by Dirk Kingma introduces what we call the _reparametrization trick_. For a Gaussian prior on z, the information layer is merely a deterministic function f(z) = mu + sigma*eps, where mu and sigma follow from the encoder. Eps is a draw from a unit Gaussian.\r\n\r\nThe according python code is as follows:\r\n    with tf.name_scope(\"Latent_space\") as scope:\r\n      self.eps = tf.random_normal(tf.shape(self.z_mu),0,1,dtype=tf.float32)\r\n      self.z = self.z_mu + tf.mul(tf.sqrt(tf.exp(z_sig_log_sq)),self.eps)   #Z is the vector in latent space\r\n# Model\r\nThese experiments use an LSTM as recurrent neural network. LSTM can depend on long term information. This is beneficial for VRAE, where the only information arises from the latent space. From the latent space, the model predicts the initial state. Throughout the sequence, the output at every step inputs into the LSTM. This way, the model knows what it just predicted\r\n\r\n# Results\r\nFortunately, the model can auto encode the basketbal trajectories with two latent variables. In [this](https://robromijnders.github.io/MDN/) post, we worked on three point shots. They're obtained from NBA games, where a tracking system outputs the X,Y and Z coordinates for the ball at 25Hz during the game. \r\n\r\nA 2 dimensional latent space allows for visualizations. For example in this image, we color the latent space according to the x coordinate from where the ball is shot.\r\n![color_x](https://github.com/RobRomijnders/VAE_rec/blob/master/images/2Dlatentspace_with_x_coordinate.png?raw=true)\r\n\r\nAnd in this scatterplot, the y coordinates color the points\r\n![color_y](https://github.com/RobRomijnders/VAE_rec/blob/master/images/2Dlatentspace_with_y_coordinate.png?raw=true)\r\n\r\n_The points in this scatterplot corresponds to the means of the latent space for data in the validation set._\r\n\r\nInterestingly, the latent space cares most about the x and y coordinate from where the ball is shot. The latent space transfers the x and y coordinate of the startpoint in exactly the horse-shoe shape that the three point line would be.\r\n\r\nIn another scatterplot, we color the points according to being a hit or miss.\r\n![color_hitmiss](https://github.com/RobRomijnders/VAE_rec/blob/master/images/2Dlatentspace_with_hit-miss.png?raw=true)\r\nThis image shows no obvious clustering that we can reason about. A reason could be as follows. To reconstruct a trajectory, it would be important to know the startpoint. These are NBA games, so you know that shots would all go directly to the basket. Misses are only slightly off from hits and many times they bounce on the rim. In that sense, the latent space wouldn't need to convey information on hit/miss probability as it doesn't lower the reconstruction loss. \r\n\r\nYou want to find it more? Here are some directions\r\n- In this [talk](https://dl.dropboxusercontent.com/u/16027344/ICML%202015%20Deep%20Learning%20Workshop/Karol%20Gregor%2C%20GOOGLE%20Deepmind.p2g/Default.html), Karol Gregor talks together his work on autoencoders, variational inference and DRAW\r\n- In [this](https://www.youtube.com/watch?v=P78QYjWh5sM) talk, Karol Gregor talks on DRAW at Nando de Freitas' course in \r\nLondon \r\n- In [this](https://www.youtube.com/watch?v=rjZL7aguLAs) talk Diederik Kingma talks at ICML on his paper [Auto encoding Variational Bayes](https://arxiv.org/abs/1312.6114)\r\nExtensions of these models\r\n- [This[(https://arxiv.org/abs/1607.00148) paper discusses the use of auto encoding principles for anomaly detection\r\n- [This](http://papers.nips.cc/paper/5352-semi-supervised-learning-with-deep-generative-models.pdf) work extends the unsupervised mechanisms of VAE to the semi-supervised case where some part of the data has labels\r\n\r\nAs always, I am curious to any comments and questions. Reach me at romijndersrob@gmail.com",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}